#!/usr/bin/python

"""
    https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60
    https://stackoverflow.com/questions/34449127/sklearn-tfidf-transformer-how-to-get-tf-idf-values-of-given-words-in-documen
    https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix
    
    Each word stem is a vocabulary feature. The TfIdf weight of that stem directly relates to its weight in the vocabulary.
    persons_vocab[person] = {"term_matrix": term_matrix, "tfidfvec": vectorizer}

    Construct a panda's dataframe with the following Structure:
    Each column is a stem/feature
    Each row is a person
    Each cell is the word weight for that person

    Each person's vocabulary will be an observation in the dataframe


"""

import sys
import os
import pickle
import pandas as pd
import numpy as np

persons_vocab = pickle.load(open('.\preprocessed_email_dump_funsize.pkl','rb'))
#person_vocabs = pickle.load(open('.\preprocessed_email_dump.pkl','rb'))



### Structure the data to be loaded to a pandas dataframe
weighted_terms = []
for person in persons_vocab:
    
    # The persons_weighted_terms dictionary will become the dataframe we perform PCA on 
    # the xpersonx key is the index of the dataframe. each row identifies a person
    # the remaining key:value pairs are term:weight
    persons_weighted_terms = {'xpersonx':person}
    
    # The tfidfvector trained on the person's corpus contains terms by index
    p_vector = persons_vocab[person]['tfidfvec']

    # The sparse term matrix resulting from vector training contains term weights by index
    # Sparse term matrices are defined by an array where row and column coordinates of only those cells with values are known.
    # array[k] = [row[k], col[k]] = data[k]
    # In the case of a sparse matrix generated by a tfidfvector from a corpus:
    # Each row is a document
    # Each column is a term
    # Each cell is a term weight.
    p_term_matrix = persons_vocab[person]['term_matrix']

    # Now to just extract the terms and weights and add them to the persons_weighted_terms dictionary 
    for doc in persons_vocab['term_matrix']:
    
    # Finally, add to the list of weighted terms.


## vocabs_df = pd.DataFrame([{},])
## vocabs_df = vocabs_df.set_index('')

#cols = word_counts.keys()
vocabs_df = pd.df()


# Standardize the data    

# Perform dimensionality reduction by PCA

# Export the resulting dataframe
